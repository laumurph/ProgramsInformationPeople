..  Copyright (C)  Paul Resnick.  Permission is granted to copy, distribute
    and/or modify this document under the terms of the GNU Free Documentation
    License, Version 1.3 or any later version published by the Free Software
    Foundation; with Invariant Sections being Forward, Prefaces, and
    Contributor List, no Front-Cover Texts, and no Back-Cover Texts.  A copy of
    the license is included in the section entitled "GNU Free Documentation
    License".

Caching Response Content
========================

You haven't experienced it yet, but if you get complicated data back from a REST API, it may take you many tries to compose and debug code to process that data in the way that you want. It is a good practice not to keep contacting a REST API to re-request the same data every time you run your program.

To avoid re-requesting the same data, we will use a programming pattern known as caching. It works like this:

1. Before doing some expensive operation (like calling requests.get), check whether the cache contains the results that would be generated by that operation.
2. If so, return the cached results.
3. If not, perform the expensive operation and save the results in the cache so you won't have to perform it again th enext time.

There are three reasons why caching is a good idea during your
software development using REST APIs:

- It reduces load on the website that is providing you data. It is always nice to be courteous when using other people's resources. Moreover, some websites impose rate limits: for example, after 15 requests in a 15 minute period, the site may start sending error responses. That will be confusing and annoying for you.
- It will make your program run faster. Connections over the Internet can take a few seconds or even tens of seconds if you are requesting a lot of data. It might not seem like much, but debugging is a lot easier when you can make a change in your program, run it, and get an almost instant response.
- It is harder to debug your processing code if the content that is coming back can change on each run of your code. It's amazing to be able to write programs that fetch real-time data like airport conditions or the latest tweets from Twitter. It can be hard to debug, however, if you are having problems that only occur on certain Tweets (e.g., those in foreign languages). When you encounter problematic data, it's helpful if you save a copy and can debug your program working on that saved, static copy of the data.

In our implementation of the caching pattern, we will use a python dictionary to store the results of the expensive operations (the calls to requests.get). Behind the scenes, when requests.get is executed, it takes the url_path and a parameters dictionary, turns them into a full url, and then fetches data from a website based on that full url. We will use that full url as a key in the caching dictionary, and the returned text from the call to requests.get as the associated value.

The code below implements the pattern described above.

.. sourcecode:: python

    def requestURL(baseurl, params = {}):
        req = requests.Request(baseurl, params)
        prepped = req.prepare()
        return prepped.url

    def get_with_caching(base_url, params_diction, cache_diction):
        full_url = requestURL(base_url, params)
        # step 1
        if full_url in cache_diction:
            # step 2
            return cache_diction[full_url]
        else:
            # step 3
            response = requests.get(base_url, params = params_diction)
            cache_diction[full_url] = response.text
            return response.text


The only problem with the code above is that the cache will disappear at the end of the execution of the python program. In order to preserve the cache between between multiple invocations of our program, we will dump that dictionary to a file and reload from that file.

The python module pickle makes it easy to save the dictionary (or any other python object) in a file. Here's a version that does that.

.. sourcecode:: python

    import requests
    import json
    import pickle

    cache_fname = "cached_results.txt"
    try:
        fobj = open(cache_fname, 'r')
        saved_cache = pickle.load(fobj)
        fobj.close()
    except:
        saved_cache = {}

    def requestURL(baseurl, params = {}):
        req = requests.Request(method = 'GET', url = baseurl, params = params)
        prepped = req.prepare()
        return prepped.url

    def get_with_caching(base_url, params_diction, cache_diction, cache_fname):
        full_url = requestURL(base_url, params_diction)
        # step 1
        if full_url in cache_diction:
            # step 2
            logging.info("retrieving cached result for " + full_url)
            return cache_diction[full_url]
        else:
            # step 3
            response = requests.get(base_url, params=params_diction)
            logging.info("adding cached result for " + full_url)
            # add to the cache and save it permanently
            cache_diction[full_url] = response.text
            fobj = open(cache_fname, "w")
            pickle.dump(cache_diction, fobj)
            fobj.close()
            return response.text

Here's an example of how we could use it with the FAA's REST API. Try saving this code in a file and running it multiple times. The first time, you'll see the logging output telling you the item was retrieved from the FAA; subsequent times it will say that it was retrieved from the cache. If you want to reset the cache to empty, just delete the file "cached_results.txt" from your file system. Or change the variable fname to a different value in the code.

.. sourcecode:: python

    import requests
    import json
    import pickle
    import logging
    logging.basicConfig(level=logging.INFO)

    cache_fname = "cached_results.txt"
    try:
        fobj = open(cache_fname, 'r')
        saved_cache = pickle.load(fobj)
        fobj.close()
    except:
        saved_cache = {}

    def requestURL(baseurl, params = {}):
        req = requests.Request(method = 'GET', url = baseurl, params = params)
        prepped = req.prepare()
        return prepped.url

    def get_with_caching(base_url, params_diction, cache_diction, cache_fname):
        full_url = requestURL(base_url, params_diction)
        # step 1
        if full_url in cache_diction:
            # step 2
            logging.info("retrieving cached result for " + full_url)
            return cache_diction[full_url]
        else:
            # step 3
            response = requests.get(base_url, params=params_diction)
            logging.info("adding cached result for " + full_url)
            # add to the cache and save it permanently
            cache_diction[full_url] = response.text
            fobj = open(cache_fname, "w")
            pickle.dump(cache_diction, fobj)
            fobj.close()
            return response.text

    dest_url = 'http://services.faa.gov/airport/status/DTW'
    d = {'format': 'json'}
    result_text = get_with_caching(dest_url, d, saved_cache, cache_fname)
    print json.loads(result_text)